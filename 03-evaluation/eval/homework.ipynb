{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd4738f-3ec5-498e-8af8-71236e421af9",
   "metadata": {},
   "source": [
    "## Homework: Search Evaluation\n",
    "\n",
    "In this homework, we will evaluate the results of vector\n",
    "search.\n",
    "\n",
    "> It's possible that your answers won't match exactly. If it's the case, select the closest one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e4df59-44f2-4a2f-b45d-9fe4ae096010",
   "metadata": {},
   "source": [
    "## Required libraries\n",
    "\n",
    "We will use minsearch and Qdrant. Make sure you have the most up-to-date versions:\n",
    "\n",
    "```bash\n",
    "pip install -U minsearch qdrant_client\n",
    "``` \n",
    "\n",
    "minsearch should be at least 0.0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a0c278-0d09-40c6-80fb-9fd8182cc040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: minsearch in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.0.4)\n",
      "Requirement already satisfied: qdrant_client in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.15.0)\n",
      "Requirement already satisfied: numpy in /usr/local/python/3.12.1/lib/python3.12/site-packages (from minsearch) (2.3.1)\n",
      "Requirement already satisfied: pandas in /usr/local/python/3.12.1/lib/python3.12/site-packages (from minsearch) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/python/3.12.1/lib/python3.12/site-packages (from minsearch) (1.7.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from qdrant_client) (1.73.1)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /home/codespace/.local/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from qdrant_client) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from qdrant_client) (6.31.1)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from qdrant_client) (2.11.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /home/codespace/.local/lib/python3.12/site-packages (from qdrant_client) (2.5.0)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas->minsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas->minsearch) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->minsearch) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scikit-learn->minsearch) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scikit-learn->minsearch) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U minsearch qdrant_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ec517-8e6a-41db-a3ae-44a602b807a8",
   "metadata": {},
   "source": [
    "## Evaluation data\n",
    "\n",
    "For this homework, we will use the same dataset we generated\n",
    "in the videos.\n",
    "\n",
    "Let's get them:\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421bba3e-5d61-4c13-878a-88f6f0f99eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f816a06-db39-46d6-8497-342c9d2eba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7ebcb-d0cb-4162-bce5-91195cc09810",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "Here, `documents` contains the documents from the FAQ database\n",
    "with unique IDs, and `ground_truth` contains generated\n",
    "question-answer pairs. \n",
    "\n",
    "Also, we will need the code for evaluating retrieval:\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47044cd1-17a7-4a13-aed1-01e9eabaf92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a5e8e4-bb41-47ab-8bfe-77aadca880aa",
   "metadata": {},
   "source": [
    "## Q1. Minsearch text\n",
    "\n",
    "Now let's evaluate our usual minsearch approach, but tweak\n",
    "the parameters. Let's use the following boosting \n",
    "params:\n",
    "\n",
    "```python\n",
    "boost = {'question': 1.5, 'section': 0.1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bbece3-64a2-4c4a-a705-04f75187716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = {'question': 1.5, 'section': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b2a5198-ae99-4bff-ab46-2f5116ee8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/llm-zoomcamp/03-evaluation/eval/minsearch.py:10: UserWarning: Now minsearch is installable via pip: 'pip install minsearch'. Remove the downloaded file and re-install it with pip.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/workspaces/llm-zoomcamp/03-evaluation/eval/minsearch.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "minsearch.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2518945-eea5-4403-b1ba-67f2aa97a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade --force-reinstall minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "587ca523-a893-469f-82f1-fc22f308ca20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7e3313574bf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\", 'id']\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad678198-da60-4387-a048-bc23f1e977fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, course):\n",
    "    boost = {'question': 1.5, 'section': 0.1}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': course},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338cd1b-a269-4c3a-9cda-8b7a5431687d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8562c6c3a2b444aac71794b88926408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_search(q['question'], q['course']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df87ed-bf1b-42de-b868-c98d9bc5a2e2",
   "metadata": {},
   "source": [
    "What's the hitrate for this approach?\n",
    "\n",
    "* 0.64\n",
    "* 0.74\n",
    "* 0.84 Correct\n",
    "* 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce7bd28-e246-47d1-931d-600721e5db0b",
   "metadata": {},
   "source": [
    "## Embeddings \n",
    "\n",
    "The latest version of minsearch also supports vector search. \n",
    "We will use it:\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f58366-cd0a-449a-a85d-5fd58f2a2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62430f2a-b2d8-49cd-8fac-b1300d8e8a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import VectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931a726-bd16-4460-9629-8bf6b0f4d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(minsearch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4b0d29-6d07-41db-960b-e4a5a098e7f0",
   "metadata": {},
   "source": [
    "We will also use TF-IDF and Singular Value Decomposition to \n",
    "create embeddings from texts. You can refer to our\n",
    "[\"Create Your Own Search Engine\" workshop](https://github.com/alexeygrigorev/build-your-own-search-engine)\n",
    "if you want to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e466d-189d-4082-a692-405455790054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695dc2ac-0139-4483-ade3-fb262a7cc78b",
   "metadata": {},
   "source": [
    "Let's create embeddings for the \"question\" field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ae10c-6d84-4e95-9dc9-c64fa46a45a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d37d55-4c96-4ace-b114-11561cb1e67f",
   "metadata": {},
   "source": [
    "## Q2. Vector search for question\n",
    "\n",
    "Now let's index these embeddings with minsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa2b81-9c1e-41d1-b6b3-f8042d14e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68bd5d-db70-4856-aa6c-58a175bf3c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
